<!doctype html>

<html class="no-js" lang="en">


<head>
	<!-- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

	Hee Suk Yoon<br>(윤희석)

	Journal Theme by https://jekyllthemes.io
	Premium + free Jekyll themes for your blog or website.

	- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -->


	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">

	<!-- Page Info -->
	<link rel="shortcut icon" href="/images/avartar.png">
	<title>Hee Suk Yoon<br>(윤희석) – Homepage</title>
	<meta name="description" content="I graduated from the Georgia Institute of Technology with a B.S. in Computer Engineering in 2021. After completing my undergraduate studies, I decided to continue my education and pursue a Ph.D. in the field of Artificial Intelligence/Deep Learning at the Korea Advanced Institute of Science and Technology (KAIST). I am currently working under the guidance of Professor Chang D. Yoo, whose expertise and leadership have been invaluable to my research. My research focuses on the reliability of Artificial Intelligence/Deep Learning technologies for various modalities, including images, videos, and natural language. I am passionate about exploring the potential of these technologies and finding ways to improve their performance and reliability in real-world applications. In my free time, I enjoy staying up-to-date with the latest developments in the field of AI/DL, as well as reading and learning about other areas of computer science and engineering. I am excited to continue my studies at KAIST and to see where my research takes me in the future!">


	
	<!-- Font Embed Code -->
	<link href="https://fonts.googleapis.com/css?family=Merriweather:300,400|Muli:400,400i,600" rel="stylesheet">
	

	<!-- Styles -->
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="stylesheet" href="/css/style.css">
	

	
	<!-- Custom Styles -->
	
	

	
	<!-- Analytics Code -->
	<!-- Google tag (gtag.js) --><script async src='https://www.googletagmanager.com/gtag/js?id=G-PCGD8891J6'></script><script>window.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());gtag('config', 'G-PCGD8891J6');</script>
	

	
	<!-- Extra Header JS Code -->
	
	
	
	<!-- icon kit -->
	
</head>


<body class="loading ajax-loading" data-site-url="http://localhost:4000" data-page-url="/">


	<header class="header">

	<div class="header-image header-image--on" style="background-image: url('/images/demo/demo-landscape.jpg');"></div>
	<div class="header-image"></div>

	<div class="header-overlay"></div>

	<div class="header__content">

		
		<h1>
			<img src="/images/avartar.png" class="header__logo__img">
		</h1>
		
		<h2>
			<a href="/" class="header__title">
				Hee Suk Yoon<br>(윤희석)
			</a>
		</h2>
		

		<h3>
		<p class="header__tagline">Ph.D. Candidate @ KAIST EE<br>Georgia Institute of Technology ECE<br>(Georgia Tech)</p>
		</h3>

		<h4>
			<a href = "mailto: hskyoon@kaist.ac.kr" class="header__email" style="color:#90b5b5">hskyoon@kaist.ac.kr</a><br>
			<a href = "mailto: hyoon962@gmail.com" class="header__email" style="color:#90b5b5">hyoon962@gmail.com (permanent)</a>
		</h4>

		<h5>
			<a href="https://www.dropbox.com/scl/fi/u8vw8a9rbzo4v19w2qfp9/HeeSukYoon_cv.pdf?rlkey=5xnu2vucwem12jjev04b3devc&dl=0" class="header__email" style="color:#90b5b5">CV</a>
			<a class="header__email">|</a>
			<a href="https://scholar.google.com/citations?user=eJ_iOQEAAAAJ&hl=en" class="header__email" style="color:#90b5b5">Google Scholar</a>
			<a class="header__email">|</a>
			<a href="https://github.com/hee-suk-yoon" class="header__email" style="color:#90b5b5">GitHub</a>
			<a class="header__email">|</a>
			<a href="https://www.linkedin.com/in/hee-suk-yoon/" class="header__email" style="color:#90b5b5">Linkedin</a>
		</h5>
	</div>

</header>


	<div class="loader"><svg width="120" height="30" viewBox="0 0 120 30" xmlns="http://www.w3.org/2000/svg"><circle cx="15" cy="15" r="15"><animate attributeName="r" from="15" to="15" begin="0s" dur="0.8s" values="15;9;15" calcMode="linear" repeatCount="indefinite" /><animate attributeName="fill-opacity" from="1" to="1" begin="0s" dur="0.8s" values="1;.5;1" calcMode="linear" repeatCount="indefinite" /></circle><circle cx="60" cy="15" r="9" fill-opacity="0.3"><animate attributeName="r" from="9" to="9" begin="0s" dur="0.8s" values="9;15;9" calcMode="linear" repeatCount="indefinite" /><animate attributeName="fill-opacity" from="0.5" to="0.5" begin="0s" dur="0.8s" values=".5;1;.5" calcMode="linear" repeatCount="indefinite" /></circle><circle cx="105" cy="15" r="15"><animate attributeName="r" from="15" to="15" begin="0s" dur="0.8s" values="15;9;15" calcMode="linear" repeatCount="indefinite" /><animate attributeName="fill-opacity" from="1" to="1" begin="0s" dur="0.8s" values="1;.5;1" calcMode="linear" repeatCount="indefinite" /></circle></svg></div>

	<div class="page-loader"></div>

	
	<div class="page">

		<div class="page__content" data-page-title="Hee Suk Yoon<br>(윤희석) – Homepage" data-image="/images/demo/demo-landscape.jpg">

			
		<section class="single">

		<div class="wrap">
			
			
		<h3 id="About Me" style="color:#545ca4">About Me</h3>
			
			
			<p>I graduated from the <a href="https://www.gatech.edu">Georgia Institute of Technology</a> with a B.S. in Computer Engineering in 2021. After completing my undergraduate studies, I decided to continue my education and pursue a Ph.D. in the field of Artificial Intelligence/Deep Learning at the <a href="https://www.kaist.ac.kr/en/">Korea Advanced Institute of Science and Technology (KAIST)</a>. I am currently working under the guidance of Professor <a href="http://sanctusfactory.com/family.php">Chang D. Yoo</a>, whose expertise and leadership have been invaluable to my research.</p>
			
			<p>My research focuses on the reliability of Artificial Intelligence/Deep Learning technologies for various modalities, including images, videos, and natural language. I am passionate about exploring the potential of these technologies and finding ways to improve their performance and reliability in real-world applications.</p>
			
			<p>In my free time, I enjoy staying up-to-date with the latest developments in the field of AI/DL, as well as reading and learning about other areas of computer science and engineering. I am excited to continue my studies at KAIST and to see where my research takes me in the future!</p>
					
			<hr />
		<h3 id="Education" style="color:#545ca4">Education</h3>
			
		<ul style="list-style-type:square; list-style-position: outside;">
		<ul style="list-style-type:square; list-style-position: outside;">
			<li>
				<p><i class="kaist-icon"></i>
				<b style="color:black">Korea Advanced Institute of Science and Technology (KAIST)</b>, <i>Daejeon, Republic of Korea</i><br>
				Ph.D. candidate (integrated) in Electrical Engineering (Artificial Intelligence/Deep Learning)<br>
				<i><SPAN STYLE="text-decoration:underline">Aug. 2021 - Present</SPAN></i><br>
				<i>Advisor: <a href="http://sanctusfactory.com/family.php">Chang D. Yoo</a></i>
				</p>
			</li>
			<br>
			<li>
				<p><i class="gt-icon"></i>
				<b style="color:black">Georgia Institute of Technology</b>, <i>Atlanta, GA, United States</i><br>
				B.S. in Computer Engineering <br>
				<i><SPAN STYLE="text-decoration:underline">graduated May 2021</SPAN></i><br>
				<i>Cumulative GPA: 3.92/4.0 (highest honors)</i>
				</p>
			</li>
		</ul>
		</ul>
			
		<hr />
			
		<h3 id="Publications" style="color:#545ca4">Publications</h3>
		<p><i>(* denotes equal contribution)</i><br>
		<i>(<i class="android-svg-icon"></i> denotes selected publications)</i></p>
		
		<ul style="list-style-type:square; list-style-position: outside;">
		<ul style="list-style-type:square; list-style-position: outside;">
			<li>
				<p>
					<b style="color:black"><i class="android-svg-icon"></i> C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion</b><br>
					<b style="color:blueviolet">Hee Suk Yoon*</b>, <a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon*</a>, Joshua Tian Jin Tee, <a href="https://speechtechnology.web.illinois.edu/mark-a-hasegawa-johnson/" style="color:#6c7a89">Mark Hasegawa-Johnson</a>, <a href="http://yingzhenli.net/home/en/" style="color:#6c7a89">Yingzhen Li</a>, <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
					ICLR 2024<br>
				</p>
			</li>
			<br>
			<li>
				<p>
					<b style="color:black">ADAMER-CTC: Connectionist Temporal Classification with Adaptive Maximum Entropy Regularization for Automatic Speech Recognition</b><br>
					SooHwan Eom, <a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon</a>, <b style="color:blueviolet">Hee Suk Yoon</b>, <a href="https://chanwcom.github.io/about_myself/" style="color:#6c7a89">Chanwoo Kim</a>, <a href="https://speechtechnology.web.illinois.edu/mark-a-hasegawa-johnson/" style="color:#6c7a89">Mark Hasegawa-Johnson</a>, <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
					ICASSP 2024<br>
				</p>
			</li>
			<br>
			<li>
				<p>
					<b style="color:black">SimPSI: A Simple Strategy to Preserve Spectral Information in Time Series Data Augmentation</b><br>
					Hyun Ryu, <a href="https://dbstjswo505.github.io" style="color:#6c7a89">Sunjae Yoon</a>, <b style="color:blueviolet">Hee Suk Yoon</b>, <a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon</a>, <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
					AAAI 2024<br>
					<a href="https://arxiv.org/abs/2312.05790" style="color:#071cec">[arxiv]</a> <a href="https://github.com/Hyun-Ryu/simpsi" style="color:#071cec">[code]</a>
				</p>
			</li>
			<br>
			<li>
				<p>
					<b style="color:black">HEAR: Hearing Enhanced Audio Response for Video-grounded Dialogue</b><br>
					<a href="https://dbstjswo505.github.io" style="color:#6c7a89">Sunjae Yoon</a>, Dahyun Kim, <a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon*</a>, <b style="color:blueviolet">Hee Suk Yoon</b>, <a href="https://sites.google.com/view/imr-lab/family/professor?authuser=0" style="color:#6c7a89">Junyeong Kim</a>, <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
					EMNLP 2023 (findings)<br>
					<a href="https://aclanthology.org/2023.findings-emnlp.797/" style="color:#071cec">[paper]</a> <a href="https://github.com/dbstjswo505/HEAR" style="color:#071cec">[code]</a>
				</p>
			</li>
			<br>
			<li>
				<p>
					<b style="color:black">One-Shot and Few-Shot Exemplification Modeling</b><br>
					<a href="https://scholar.google.com/citations?user=V5XGb3oAAAAJ&hl=en" style="color:#6c7a89">John Harvill</a>, <b style="color:blueviolet">Hee Suk Yoon</b>, <a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon</a>, <a href="https://speechtechnology.web.illinois.edu/mark-a-hasegawa-johnson/" style="color:#6c7a89">Mark Hasegawa-Johnson</a> and <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
					EMNLP 2023 Workshop on Generation, Evaluation & Metrics (GEM 2023)<br>
				</p>
			</li>
			<br>
			<li>
				<p>
				<b style="color:black"><i class="android-svg-icon"></i> Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P) Transduction</b><br>
				<a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon*</a>, <b style="color:blueviolet">Hee Suk Yoon*</b>, Dhananjaya Gowda, SooHwan Eom, Daehyeok Kim, <a href="https://scholar.google.com/citations?user=V5XGb3oAAAAJ&hl=en" style="color:#6c7a89">John Harvill</a>, Heting Gao, <a href="https://speechtechnology.web.illinois.edu/mark-a-hasegawa-johnson/" style="color:#6c7a89">Mark Hasegawa-Johnson</a>, <a href="https://chanwcom.github.io/about_myself/" style="color:#6c7a89">Chanwoo Kim</a>, <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
				INTERSPEECH 2023<br>
				<a href="https://www.isca-speech.org/archive/interspeech_2023/yoon23d_interspeech.html" style="color:#071cec">[paper]</a> <a href="https://arxiv.org/abs/2308.08442" style="color:#071cec">[arxiv]</a> <a href="https://www.dropbox.com/scl/fi/gku51qt9fls679nhe9q4b/interspeech2023_ExposureG2P.pdf?rlkey=su306c1qn6m8d20ylbx305ltz&dl=0" style="color:#071cec">[poster]</a>
				</p>
			</li>
			<br>
			<li>
				<p>
				<b style="color:black">One-Shot Exemplification Modeling via Latent Sense Representations</b><br>
				<a href="https://scholar.google.com/citations?user=V5XGb3oAAAAJ&hl=en" style="color:#6c7a89">John Harvill</a>, <b style="color:blueviolet">Hee Suk Yoon</b>, <a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon</a>, <a href="https://speechtechnology.web.illinois.edu/mark-a-hasegawa-johnson/" style="color:#6c7a89">Mark Hasegawa-Johnson</a> and <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
				ACL 2023 Workshop on Representation Learning for NLP (RepL4NLP 2023)<br>
				<a href="https://aclanthology.org/2023.repl4nlp-1.25/" style="color:#071cec">[paper]</a> <a href="https://www.dropbox.com/scl/fi/c2re6nniw3r08zlj2ps5j/acl2023_exemplication.pdf?rlkey=xc5deb1a0nlds7k4tno32zisl&dl=0" style="color:#071cec">[poster]</a>
				</p>
			</li>
			<br>
			<li>
				<p>
				<b style="color:black"><i class="android-svg-icon"></i> INTapt: Information-Theoretic Adversarial Prompt Tuning for Enhanced Non-Native Speech Recognition</b><br>
				<a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon*</a>, <b style="color:blueviolet">Hee Suk Yoon*</b>, <a href="https://scholar.google.com/citations?user=V5XGb3oAAAAJ&hl=en" style="color:#6c7a89">John Harvill</a>, <a href="https://speechtechnology.web.illinois.edu/mark-a-hasegawa-johnson/" style="color:#6c7a89">Mark Hasegawa-Johnson</a>, <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
				ACL 2023 (findings)<br>
				<a href="https://aclanthology.org/2023.findings-acl.627/" style="color:#071cec">[paper]</a> <a href="https://arxiv.org/abs/2305.16371" style="color:#071cec">[arxiv]</a> 
				</p>
			</li>
			<br>
			<li>
				<p>
				<b style="color:black"><i class="android-svg-icon"></i> ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration Measure</b><br>
				<b style="color:blueviolet">Hee Suk Yoon*</b>, Joshua Tian Jin Tee*, <a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon</a>, <a href="https://dbstjswo505.github.io" style="color:#6c7a89">Sunjae Yoon</a>, Gwangsu Kim, <a href="http://yingzhenli.net/home/en/" style="color:#6c7a89">Yingzhen Li</a>, <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
				ICLR 2023<br>
				<a href="https://openreview.net/forum?id=bHW9njOSON" style="color:#071cec">[paper]</a> <a href="http://arxiv.org/abs/2303.02472" style="color:#071cec">[arxiv]</a> <a href="https://www.dropbox.com/scl/fi/u3n649r3fxee2ghsb11na/iclr2023_esd.pdf?rlkey=x331urmkm7sljj3uz4sgq1s66&dl=0" style="color:#071cec">[poster]</a> <a href="https://github.com/hee-suk-yoon/ESD" style="color:#071cec">[code]</a>
				</p>
			</li>
			<br>
			<li>
				<p>
				<b style="color:black">Counterfactual Two-stage Debiasing for Video Corpus Moment Retrieval</b><br>
				<a href="https://dbstjswo505.github.io" style="color:#6c7a89">Sunjae Yoon</a>, Ji Woo Hong, SooHwan Eom, <b style="color:blueviolet">Hee Suk Yoon</b>, <a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon</a>, Daehyeok Kim, <a href="https://sites.google.com/view/imr-lab/family/professor?authuser=0" style="color:#6c7a89">Junyeong Kim</a>, <a href="https://chanwcom.github.io/about_myself/" style="color:#6c7a89">Chanwoo Kim</a>, <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
				ICASSP 2023 (oral)<br>
				<a href="https://ieeexplore.ieee.org/document/10095182" style="color:#071cec">[paper]</a>
				</p>
			</li>
			<br>
			<li>
				<p>
				<b style="color:black"><i class="android-svg-icon"></i> SMSMix: Sense Maintained Sentence Mixup for Word Sense Disambiguation</b><br>
				<b style="color:blueviolet">Hee Suk Yoon*</b>, <a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon*</a>, <a href="https://scholar.google.com/citations?user=V5XGb3oAAAAJ&hl=en" style="color:#6c7a89">John Harvill</a>, <a href="https://dbstjswo505.github.io" style="color:#6c7a89">Sunjae Yoon</a>, <a href="https://speechtechnology.web.illinois.edu/mark-a-hasegawa-johnson/" style="color:#6c7a89">Mark Hasegawa-Johnson</a>, <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
				EMNLP 2022 (findings)<br>
				<a href="https://aclanthology.org/2022.findings-emnlp.107/" style="color:#071cec">[paper]</a> <a href="https://arxiv.org/abs/2212.07072" style="color:#071cec">[arxiv]</a>  
				</p>
			</li>
			<br>
			<li>
				<p>
				<b style="color:black">Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue</b><br>
				<a href="https://dbstjswo505.github.io" style="color:#6c7a89">Sunjae Yoon</a>, <a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon</a>, <b style="color:blueviolet">Hee Suk Yoon</b>, <a href="https://sites.google.com/view/imr-lab/family/professor?authuser=0" style="color:#6c7a89">Junyeong Kim</a>, <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
				EMNLP 2022<br>
				<a href="https://aclanthology.org/2022.emnlp-main.280/" style="color:#071cec">[paper]</a> <a href="https://arxiv.org/abs/2212.05765" style="color:#071cec">[arxiv]</a> <a href="https://www.dropbox.com/scl/fi/by55l3mao5dqevjlwjv94/emnlp2022_THAM.pdf?rlkey=c1360woyrp15yu5rd0g6dpalb&dl=0" style="color:#071cec">[poster]</a>
				</p>
			</li>
			<br>
			<li>
				<p>
				<b style="color:black">Selective Query-Guided Debiasing for Video Corpus Moment Retrieval</b><br>
				<a href="https://dbstjswo505.github.io" style="color:#6c7a89">Sunjae Yoon</a>, Ji Woo Hong, <a href="https://esyoon7.github.io" style="color:#6c7a89">Eunseop Yoon</a>, Dahyun Kim, <a href="https://sites.google.com/view/imr-lab/family/professor?authuser=0" style="color:#6c7a89">Junyeong Kim</a>, <b style="color:blueviolet">Hee Suk Yoon</b>, <a href="http://sanctusfactory.com/family.php" style="color:#6c7a89">Chang D. Yoo</a><br>
				ECCV 2022<br>
				<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136960183.pdf" style="color:#071cec">[paper]</a> <a href="https://arxiv.org/abs/2210.08714" style="color:#071cec">[arxiv]</a> <a href="https://github.com/dbstjswo505/SQuiDNet" style="color:#071cec">[code]</a>
				</p>
			</li>
		</ul>	
		</ul>
		
		<hr />
		<h3 id="Academic Activities" style="color:#545ca4">Academic Activities</h3>
		<h4 id="Reviewer Experience" style="color:#545ca4">Journal Reviewing</h4>
		<ul style="list-style-type:square; list-style-position: outside;">
		<ul style="list-style-type:square; list-style-position: outside;">		
			<li>
				<p>
				<b style="color:black">Transactions on Machine Learning Research (TMLR)</b>
				</p>
			</li>	
		</ul>
		</ul>
		<h4 id="Reviewer Experience" style="color:#545ca4">Conference Reviewing</h4>
		<ul style="list-style-type:square; list-style-position: outside;">
		<ul style="list-style-type:square; list-style-position: outside;">
			<li>
				<p>
				<b style="color:black">Conference on Computer Vision and Pattern Recognition (CVPR):</b> 2024
				</p>
			</li>	
			<li>
				<p>
				<b style="color:black">North American Chapter of the Association for Computational Linguistics (NAACL):</b> 2024
				</p>
			</li>		
			<li>
				<p>
				<b style="color:black">Association for Computational Linguistics (ACL):</b> 2023
				</p>
			</li>	
			<li>
				<p>
				<b style="color:black">International Conference on Acoustics, Speech & Signal Processing (ICASSP):</b> 2023, 2024
				</p>
			</li>	
			<li>
				<p>
				<b style="color:black">Empirical Methods on Natural Language Processing (EMNLP):</b> 2022, 2023
				</p>
			</li>	
			<li>
				<p>
				<b style="color:black">International Conference on Learning Representations Tiny Papers Track (ICLR TinyPapers):</b> 2024
				</p>
			</li>
		</ul>
		</ul>
		<h4 id="Teaching Assistance" style="color:#545ca4">Teaching Assistance</h4>
		<ul style="list-style-type:square; list-style-position: outside;">
		<ul style="list-style-type:square; list-style-position: outside;">
				<li>
					<p>
					<b style="color:black">Introduction to Machine Learning</b> 2023 Fall
					</p>
				</li>	
				<li>
					<p>
					<b style="color:black">Introduction to Reinforcement Learning:</b> 2023 Spring
					</p>
				</li>	
				<li>
					<p>
					<b style="color:black">Signals and Systems:</b> 2022 Spring, 2022 Fall
					</p>
				</li>	
				<li>
					<p>
					<b style="color:black">Hwaseong City-KAIST Semiconductor Specialized Curriculum - Large Language Models</b> 2023
					</p>
				</li>
				<li>
					<p>
					<b style="color:black">Seongnam-KAIST Next Generation ICT Research Center EE Co-op+ Joint Research Program</b> 2023 Fall
					</p>
				</li>	
				<li>
					<p>
					<b style="color:black">Seongnam-KAIST Next Generation ICT Research Center Machine Learning and Big Data Course:</b> 2021, 2022, 2023
					</p>
				</li>	

		</ul>
		</ul>
		<hr />
		<h3 id="Projects" style="color:#545ca4">Projects</h3>
		<ul style="list-style-type:square; list-style-position: outside;">
		<ul style="list-style-type:square; list-style-position: outside;">
			<li>
				<p>
				<b style="color:black">Development of Uncertainty-Aware Agents Learning by Asking Questions</b><br>
				<i><SPAN STYLE="text-decoration:underline">2022-03-01 ~ 2027-03-01</SPAN></i><br>
				<i>Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (Role: Operator)</i>
				</p>
			</li>
			<li>
				<p>
				<b style="color:black">Multi-modal Generative AI for Summarization</b><br>
				<i><SPAN STYLE="text-decoration:underline">2023-09-01 ~ 2024-09-01</SPAN></i><br>
				<i>Samsung Speech Recognition & Natural Language Processing Lab (Role: Supporter)</i>
				</p>
			</li>
			<li>
				<p>
				<b style="color:black">Visual Dialogue System: Developing Visual and Language Capabilities for AI-Based Dialogue Systems</b><br>
				<i><SPAN STYLE="text-decoration:underline">2023-01-01~</SPAN></i><br>
				<i>Korea Telecom (KT) AI2XL Laboratory (Role: Operator)</i>
				</p>
			</li>
			<li>
				<p>
				<b style="color:black">Enhancing CD SEM Image Quality and Inter-Facility Image Transfer Technology using Deep Learning</b><br>
				<i><SPAN STYLE="text-decoration:underline">2021-06-01 ~ 2023-06-01</SPAN></i><br>
				<i>Samsung Metrology & Inspection (Role: Operator)</i>
				</p>
			</li>
			<li>
				<p>
				<b style="color:black">Prediction of Relative Object Sizes in Images using Deep Learning</b><br>
				<i><SPAN STYLE="text-decoration:underline">2021-06-01 ~ 2021-12-31</SPAN></i><br>
				<i>U-AIM (Role: Operator)</i>
				</p>
			</li>
		</ul>
		</ul>
		
		</div>	
		</section>
		
		</div>

	</div>


	<footer class="footer">

	<div class="footer__copyright">
		<span>© 2024 Hee Suk Yoon</span>
		<a href="https://jekyllthemes.io" target="_blank">Jekyll Themes</a>
	</div>

</footer>


	<!-- Javascript Assets -->
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
	<script src="/js/plugins-min.js"></script>
	<script src="/js/journal-min.js"></script>

	
	<!-- Extra Footer JS Code -->
	
	


</body>

</html>
